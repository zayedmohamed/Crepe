{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zayedmohamed/Crepe/blob/master/train_keras_tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "JLf2Y0-FugZ6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# How to train Keras model x20 times faster with TPU for free\n",
        "\n",
        "An overview of the workflow,\n",
        "\n",
        "- Build a Keras model for training in functional API with static input batch_size.\n",
        "- Convert Keras model to TPU model.\n",
        "- Train the TPU model with static batch_size * 8 and save the weights to file.\n",
        "- Build a Keras model for inference with the same structure but variable batch input size.\n",
        "- Load the model weights.\n",
        "- Predict with the inferencing model."
      ]
    },
    {
      "metadata": {
        "id": "e6SnkOIxnoK5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.python.keras.layers import Input, LSTM, Bidirectional, Dense, Embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ofnV3kksnz8n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "150704a0-3c8e-4561-aa0d-0b6beb450512"
      },
      "cell_type": "code",
      "source": [
        "# Number of words to consider as features\n",
        "max_features = 10000\n",
        "# Cut texts after this number of words (among top max_features most common words)\n",
        "maxlen = 500\n",
        "\n",
        "# Load data\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Reverse sequences\n",
        "x_train = [x[::-1] for x in x_train]\n",
        "x_test = [x[::-1] for x in x_test]\n",
        "\n",
        "# Pad sequences\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yniRY7D2vJv2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Static input Batch size\n",
        "Input pipelines running on CPU and GPU are mostly free from the static shape requirement, while in the XLA/TPU environment, static shapes and batch size is imposed.\n",
        "\n",
        "The Cloud TPU contains 8 TPU cores, which operate as independent processing units. The TPU is not fully utilized unless all eight cores are used. To fully speed up the training with vectorization, we can choose a larger batch size compared to training the same model on a single GPU. A total batch size of 1024 (128 per core) is generally a good starting point.\n",
        "\n",
        "In case you are going to train a larger model where the batch size is too large, try slowly reduce the batch size until it fits in TPU memory, just making sure that the total batch size is a multiple of 64 (the per-core batch size should be a multiple of 8).\n",
        "\n",
        "It is also worth to mention when training with larger batch size; it is generally safe to increase the learning rate of the optimizer to allow even faster convergence. You can find a reference in this paper - \"[Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour](https://https://arxiv.org/pdf/1706.02677.pdf)\".\n",
        "\n",
        "In Keras, to define a static batch size, we use its functional API and then specify the `batch_size` parameter for the Input layer. Notice that the model builds in a function which takes a `batch_size` parameter so we can come back later to make another model for inferencing runs on CPU or GPU which takes variable batch size inputs."
      ]
    },
    {
      "metadata": {
        "id": "4Gy7x4TVn7Fh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_model(batch_size=None):\n",
        "  source = Input(shape=(maxlen,), batch_size=batch_size, dtype=tf.int32, name='Input')\n",
        "  embedding = Embedding(input_dim=max_features, output_dim=128, name='Embedding')(source)\n",
        "  # lstm = Bidirectional(LSTM(32, name = 'LSTM'), name='Bidirectional')(embedding)\n",
        "  lstm = LSTM(32, name = 'LSTM')(embedding)\n",
        "  predicted_var = Dense(1, activation='sigmoid', name='Output')(lstm)\n",
        "  model = tf.keras.Model(inputs=[source], outputs=[predicted_var])\n",
        "  model.compile(\n",
        "      optimizer=tf.train.RMSPropOptimizer(learning_rate=0.01),\n",
        "      loss='binary_crossentropy',\n",
        "      metrics=['acc'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Ksfi-_6x4XG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Also, use `tf.train.Optimizer` instead of a standard Keras optimizer since Keras optimizer support is still experimental for TPU."
      ]
    },
    {
      "metadata": {
        "id": "WSu61ynDoPX7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "4efaa733-ae43-4ab3-8505-b6bbe44ac9e7"
      },
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "training_model = make_model(batch_size = 128)\n",
        "training_model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input (InputLayer)           (128, 500)                0         \n",
            "_________________________________________________________________\n",
            "Embedding (Embedding)        (128, 500, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "LSTM (LSTM)                  (128, 32)                 20608     \n",
            "_________________________________________________________________\n",
            "Output (Dense)               (128, 1)                  33        \n",
            "=================================================================\n",
            "Total params: 1,300,641\n",
            "Trainable params: 1,300,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4YFpAxKlynts",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Convert Keras model to TPU model\n",
        "The `tf.contrib.tpu.keras_to_tpu_model` function converts a tf.keras model to an equivalent TPU version."
      ]
    },
    {
      "metadata": {
        "id": "4QY_JMZNoa-B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "dc27240e-6c0c-4599-8036-ae6351511eab"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "# This address identifies the TPU we'll use when configuring TensorFlow.\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    training_model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\n",
        "\n",
        "tpu_model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (b'grpc://10.115.195.114:8470') for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 14291680080413639861)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 8114354152376501122)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 14622084438864888236)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 16675989505216646498)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7336732595318902999)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 17344505308830462699)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 12272618527804351087)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 14545632421272590475)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 11854635024143697199)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 16760744186365077461)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 16305098218149038255)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 391142445039076046)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input (InputLayer)           (128, 500)                0         \n",
            "_________________________________________________________________\n",
            "Embedding (Embedding)        (128, 500, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "LSTM (LSTM)                  (128, 32)                 20608     \n",
            "_________________________________________________________________\n",
            "Output (Dense)               (128, 1)                  33        \n",
            "=================================================================\n",
            "Total params: 1,300,641\n",
            "Trainable params: 1,300,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5C6W3oSdzC5R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We then use the standard Keras methods to train, save the weights and evaluate the model. Notice that the `batch_size` is set to eight times of the model input `batch_size` since the input samples are evenly distributed to run on 8 TPU cores. "
      ]
    },
    {
      "metadata": {
        "id": "fpwPS-Z-po-9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1125
        },
        "outputId": "44b97bf5-1996-4482-aece-b132a8ba5aee"
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "history = tpu_model.fit(x_train, y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=128 * 8,\n",
        "                    validation_split=0.2)\n",
        "tpu_model.save_weights('./tpu_model.h5', overwrite=True)\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 5000 samples\n",
            "Epoch 1/20\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(128,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(128, 500), dtype=tf.int32, name='Input_10'), TensorSpec(shape=(128, 1), dtype=tf.float32, name='Output_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for Input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 2.755854845046997 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "23552/25000 [===========================>..] - ETA: 0s - loss: 0.6931 - acc: 0.5026INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(53,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(53, 500), dtype=tf.int32, name='Input_10'), TensorSpec(shape=(53, 1), dtype=tf.float32, name='Output_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for Input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 3.7938554286956787 secs\n",
            "24576/25000 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5034INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(128,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(128, 500), dtype=tf.int32, name='Input_10'), TensorSpec(shape=(128, 1), dtype=tf.float32, name='Output_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for Input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 4.910218954086304 secs\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(113,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(113, 500), dtype=tf.int32, name='Input_10'), TensorSpec(shape=(113, 1), dtype=tf.float32, name='Output_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for Input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 5.586439847946167 secs\n",
            "25000/25000 [==============================] - 36s 1ms/step - loss: 0.6931 - acc: 0.5033 - val_loss: 0.6931 - val_acc: 0.4960\n",
            "Epoch 2/20\n",
            "25000/25000 [==============================] - 3s 136us/step - loss: 0.6931 - acc: 0.5088 - val_loss: 0.6933 - val_acc: 0.4948\n",
            "Epoch 3/20\n",
            "25000/25000 [==============================] - 3s 133us/step - loss: 0.6931 - acc: 0.5042 - val_loss: 0.6930 - val_acc: 0.4964\n",
            "Epoch 4/20\n",
            "25000/25000 [==============================] - 3s 132us/step - loss: 0.6929 - acc: 0.5114 - val_loss: 0.6948 - val_acc: 0.4938\n",
            "Epoch 5/20\n",
            "25000/25000 [==============================] - 3s 132us/step - loss: 0.6913 - acc: 0.5266 - val_loss: 0.6995 - val_acc: 0.4950\n",
            "Epoch 6/20\n",
            "25000/25000 [==============================] - 3s 137us/step - loss: 0.7015 - acc: 0.5735 - val_loss: 0.6768 - val_acc: 0.5590\n",
            "Epoch 7/20\n",
            "25000/25000 [==============================] - 3s 136us/step - loss: 0.6580 - acc: 0.6278 - val_loss: 0.6518 - val_acc: 0.6170\n",
            "Epoch 8/20\n",
            "25000/25000 [==============================] - 3s 133us/step - loss: 0.6166 - acc: 0.6790 - val_loss: 0.5292 - val_acc: 0.7450\n",
            "Epoch 9/20\n",
            "25000/25000 [==============================] - 3s 135us/step - loss: 0.6079 - acc: 0.7164 - val_loss: 0.4826 - val_acc: 0.8144\n",
            "Epoch 10/20\n",
            "25000/25000 [==============================] - 3s 131us/step - loss: 0.4738 - acc: 0.7894 - val_loss: 0.4679 - val_acc: 0.7702\n",
            "Epoch 11/20\n",
            "25000/25000 [==============================] - 3s 132us/step - loss: 0.4536 - acc: 0.8052 - val_loss: 0.3596 - val_acc: 0.8532\n",
            "Epoch 12/20\n",
            "25000/25000 [==============================] - 3s 133us/step - loss: 0.3621 - acc: 0.8479 - val_loss: 0.4422 - val_acc: 0.8230\n",
            "Epoch 13/20\n",
            "25000/25000 [==============================] - 3s 134us/step - loss: 0.2913 - acc: 0.8824 - val_loss: 0.3000 - val_acc: 0.8798\n",
            "Epoch 14/20\n",
            "25000/25000 [==============================] - 3s 135us/step - loss: 0.2432 - acc: 0.9052 - val_loss: 0.1748 - val_acc: 0.9384\n",
            "Epoch 15/20\n",
            "25000/25000 [==============================] - 3s 132us/step - loss: 0.2069 - acc: 0.9205 - val_loss: 0.1854 - val_acc: 0.9402\n",
            "Epoch 16/20\n",
            "25000/25000 [==============================] - 3s 134us/step - loss: 0.1672 - acc: 0.9384 - val_loss: 0.1466 - val_acc: 0.9550\n",
            "Epoch 17/20\n",
            "25000/25000 [==============================] - 3s 134us/step - loss: 0.1277 - acc: 0.9567 - val_loss: 0.0887 - val_acc: 0.9756\n",
            "Epoch 18/20\n",
            "25000/25000 [==============================] - 3s 135us/step - loss: 0.1175 - acc: 0.9610 - val_loss: 0.0703 - val_acc: 0.9804\n",
            "Epoch 19/20\n",
            "25000/25000 [==============================] - 3s 136us/step - loss: 0.1140 - acc: 0.9666 - val_loss: 0.0554 - val_acc: 0.9848\n",
            "Epoch 20/20\n",
            "25000/25000 [==============================] - 3s 133us/step - loss: 0.0767 - acc: 0.9739 - val_loss: 0.0545 - val_acc: 0.9856\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "--- 103.70809006690979 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TSCFN9B6zUs8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I set up an experiment to compare the training speed between a single GTX1070 running locally on my Windows PC and TPU on Colab, here is the result.\n",
        "\n",
        "Both GPU and TPU takes the input batch size of 128,\n",
        "\n",
        "GPU: **179 seconds per epoch.** 20 epochs reach 76.9% validation accuracy, total  3600 seconds.\n",
        "\n",
        "TPU: **5 seconds per epoch** except for the very first epoch which takes 36 seconds. 20 epochs reach 97.39% validation accuracy, total 104 seconds.\n",
        "\n",
        "The validation accuracy for TPU after 20 epochs are higher than GPU may be caused by training 8 batches of the mini-batch size of 128 samples at a time. "
      ]
    },
    {
      "metadata": {
        "id": "pH3hkyg9z7yt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Inferencing on CPU\n",
        "Once we have the model weights, we can load it as usual and make predictions on another device like CPU or GPU. We also want the inferencing model to accept flexible input batch size, that can be done with the previous make_model() function.\n",
        "\n",
        "You can see the inferencing model now takes variable input samples,"
      ]
    },
    {
      "metadata": {
        "id": "uhFVP8snqjUw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "faa4dc76-8e86-4139-dde4-1dc7486f8e35"
      },
      "cell_type": "code",
      "source": [
        "inferencing_model = make_model(batch_size=None)\n",
        "inferencing_model.load_weights('./tpu_model.h5')\n",
        "inferencing_model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input (InputLayer)           (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "Embedding (Embedding)        (None, 500, 128)          1280000   \n",
            "_________________________________________________________________\n",
            "LSTM (LSTM)                  (None, 32)                20608     \n",
            "_________________________________________________________________\n",
            "Output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,300,641\n",
            "Trainable params: 1,300,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W6w90AzC0I9i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then you can use the standard `fit(), evaluate() ` functions with the inferencing model."
      ]
    },
    {
      "metadata": {
        "id": "0FYVqtafq-ZM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3f8e9dc9-e4d4-4169-dcf8-dc4f15f49af7"
      },
      "cell_type": "code",
      "source": [
        "inferencing_model.evaluate(x_test, y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 74s 3ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5920307851076126, 0.8178]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "KlwwxPYqsC1n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "e0bb5f6e-bf6d-410e-e983-bb82a9c3cffe"
      },
      "cell_type": "code",
      "source": [
        "tpu_model.evaluate(x_test, y_test, batch_size=128 * 8)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23552/25000 [===========================>..] - ETA: 0sINFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(53,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(53, 500), dtype=tf.int32, name='Input_10'), TensorSpec(shape=(53, 1), dtype=tf.float32, name='Output_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for Input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 10.642410278320312 secs\n",
            "25000/25000 [==============================] - 17s 691us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5920634329032898, 0.8177599998283386]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "ya90nMfFsRGd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7a08d30c-b179-4926-e793-0ee263415ac4"
      },
      "cell_type": "code",
      "source": [
        "tpu_model.evaluate(x_test, y_test, batch_size=128 * 8)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 1s 46us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5920634329032898, 0.8177599998283386]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "WOJm5G4NsbQr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d931e372-9e64-440a-dcb7-97cfb6508e49"
      },
      "cell_type": "code",
      "source": [
        "inferencing_model.predict(x_test[:10])> 0.5"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "SfcepV0asjoR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6309d222-6ec3-4599-f5e8-df2e55c38fa0"
      },
      "cell_type": "code",
      "source": [
        "y_test[:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 1, 1, 1, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "g44Zpg3qsoaB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "311b7e37-ef3b-44b1-9d18-ca0628747e3a"
      },
      "cell_type": "code",
      "source": [
        "tpu_model.predict_on_batch(x_train[:128 * 8])>0.5"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=infer (# of cores 8), [TensorSpec(shape=(128, 500), dtype=tf.int32, name='Input_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for Input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 12.780016660690308 secs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       ...,\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "j372Z-gDs0Ge",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Download the trained model weights to your local file system\n"
      ]
    },
    {
      "metadata": {
        "id": "NncPE8Vbs52z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('./tpu_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}